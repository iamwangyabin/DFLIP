"""
Qwen Vision æ¨¡å‹å‰å‘ä¼ æ’­æµ‹è¯•è„šæœ¬
ä¸éœ€è¦è®­ç»ƒï¼Œä»…æµ‹è¯•éšæœºè¾“å…¥çš„è¾“å‡º

è¿™ä¸ªè„šæœ¬ç”¨æ¥éªŒè¯DFLIPProfileræ¨¡å‹çš„forward passæ˜¯å¦æ­£ç¡®è¿è¡Œ
"""

import torch
import torch.nn as nn
from dflip_models.qwen_vision import DFLIPProfiler


def test_qwen_vision_forward():
    """æµ‹è¯•Qwen Visionæ¨¡å‹çš„å‰å‘ä¼ æ’­"""
    
    print("=" * 80)
    print("Qwen Vision Forward Pass Test")
    print("=" * 80)
    
    # 1. åˆå§‹åŒ–æ¨¡å‹
    print("\n[1] åˆå§‹åŒ–æ¨¡å‹...")
    try:
        model = DFLIPProfiler(
            model_name="Qwen/Qwen2.5-VL-7B-Instruct",
            num_generators=10,
            extract_layers=[6, 12, 18]
        )
        print("âœ“ æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âœ— æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # 2. è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
    print("\n[2] è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼...")
    model.eval()
    print("âœ“ æ¨¡å‹è®¾ç½®ä¸ºevalæ¨¡å¼")
    
    # 3. åˆ›å»ºéšæœºè¾“å…¥
    print("\n[3] åˆ›å»ºéšæœºè¾“å…¥...")
    batch_size = 2
    num_channels = 3
    height = 448
    width = 448
    
    # åˆ›å»ºéšæœºåƒç´ å€¼å¼ é‡ (B, C, H, W)
    pixel_values = torch.randn(batch_size, num_channels, height, width)
    print(f"âœ“ åˆ›å»ºéšæœºè¾“å…¥å¼ é‡: {pixel_values.shape}")
    print(f"  - Batch size: {batch_size}")
    print(f"  - Channels: {num_channels}")
    print(f"  - Height: {height}")
    print(f"  - Width: {width}")
    
    # 4. å‰å‘ä¼ æ’­ (ä¸è®¡ç®—æ¢¯åº¦)
    print("\n[4] æ‰§è¡Œå‰å‘ä¼ æ’­...")
    try:
        with torch.no_grad():
            outputs = model.forward(pixel_values, return_features=True)
        print("âœ“ å‰å‘ä¼ æ’­æˆåŠŸ")
    except Exception as e:
        print(f"âœ— å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # 5. æ£€æŸ¥è¾“å‡º
    print("\n[5] æ£€æŸ¥è¾“å‡º...")
    print(f"\nè¾“å‡ºå­—å…¸åŒ…å«çš„key: {list(outputs.keys())}")
    
    # æ£€æŸ¥detectionè¾“å‡º
    if 'detection_logits' in outputs:
        det_logits = outputs['detection_logits']
        print(f"\n  ğŸ“Š Detection Logits:")
        print(f"     - Shape: {det_logits.shape}")
        print(f"     - Expected: ({batch_size}, 2)")
        print(f"     - Min: {det_logits.min():.4f}, Max: {det_logits.max():.4f}")
        print(f"     - Mean: {det_logits.mean():.4f}, Std: {det_logits.std():.4f}")
        
        # è½¬æ¢ä¸ºæ¦‚ç‡
        det_probs = torch.softmax(det_logits, dim=-1)
        print(f"     - Softmaxæ¦‚ç‡: {det_probs[0].tolist()}")
        assert det_logits.shape == (batch_size, 2), "Detection logits shapeä¸æ­£ç¡®"
        print(f"     âœ“ ShapeéªŒè¯é€šè¿‡")
    
    # æ£€æŸ¥identificationè¾“å‡º
    if 'identification_logits' in outputs:
        id_logits = outputs['identification_logits']
        print(f"\n  ğŸ·ï¸ Identification Logits:")
        print(f"     - Shape: {id_logits.shape}")
        print(f"     - Expected: ({batch_size}, 10)")
        print(f"     - Min: {id_logits.min():.4f}, Max: {id_logits.max():.4f}")
        print(f"     - Mean: {id_logits.mean():.4f}, Std: {id_logits.std():.4f}")
        
        # è½¬æ¢ä¸ºæ¦‚ç‡
        id_probs = torch.softmax(id_logits, dim=-1)
        top_k = torch.topk(id_probs[0], k=3)
        print(f"     - Top-3ç”Ÿæˆå™¨: {top_k.indices.tolist()}, æ¦‚ç‡: {top_k.values.tolist()}")
        assert id_logits.shape == (batch_size, 10), "Identification logits shapeä¸æ­£ç¡®"
        print(f"     âœ“ ShapeéªŒè¯é€šè¿‡")
    
    # æ£€æŸ¥localizationè¾“å‡º
    if 'localization_mask' in outputs:
        loc_mask = outputs['localization_mask']
        print(f"\n  ğŸ¯ Localization Mask:")
        print(f"     - Shape: {loc_mask.shape}")
        print(f"     - Expected: ({batch_size}, 1, 448, 448)")
        print(f"     - Min: {loc_mask.min():.4f}, Max: {loc_mask.max():.4f}")
        print(f"     - Mean: {loc_mask.mean():.4f}, Std: {loc_mask.std():.4f}")
        assert loc_mask.shape == (batch_size, 1, 448, 448), "Localization mask shapeä¸æ­£ç¡®"
        print(f"     âœ“ ShapeéªŒè¯é€šè¿‡")
    
    # æ£€æŸ¥ç‰¹å¾è¾“å‡º
    if 'binary_features' in outputs:
        bin_feat = outputs['binary_features']
        print(f"\n  ğŸ”¹ Binary Task Features:")
        print(f"     - Shape: {bin_feat.shape}")
        print(f"     - Expected: ({batch_size}, 1024)")
        assert bin_feat.shape[0] == batch_size, "Binary features batch sizeä¸æ­£ç¡®"
        print(f"     âœ“ ShapeéªŒè¯é€šè¿‡")
    
    if 'multiclass_features' in outputs:
        multi_feat = outputs['multiclass_features']
        print(f"\n  ğŸ”¸ Multiclass Task Features:")
        print(f"     - Shape: {multi_feat.shape}")
        print(f"     - Expected: ({batch_size}, 1024)")
        assert multi_feat.shape[0] == batch_size, "Multiclass features batch sizeä¸æ­£ç¡®"
        print(f"     âœ“ ShapeéªŒè¯é€šè¿‡")
    
    if 'spatial_features' in outputs:
        spatial_feat = outputs['spatial_features']
        print(f"\n  ğŸ”º Spatial Features:")
        print(f"     - Shape: {spatial_feat.shape}")
        print(f"     - Expected: ({batch_size}, 1024, H, W)")
        assert spatial_feat.shape[0] == batch_size, "Spatial features batch sizeä¸æ­£ç¡®"
        print(f"     âœ“ ShapeéªŒè¯é€šè¿‡")
    
    # 6. æµ‹è¯•predictæ–¹æ³•
    print("\n[6] æµ‹è¯•predictæ–¹æ³•...")
    try:
        with torch.no_grad():
            predictions = model.predict(pixel_values, threshold=0.5)
        print("âœ“ Predictæ–¹æ³•æˆåŠŸ")
        
        print(f"\né¢„æµ‹ç»“æœ:")
        print(f"  - is_fake shape: {predictions['is_fake'].shape}")
        print(f"    å€¼: {predictions['is_fake'].tolist()}")
        print(f"  - fake_probs shape: {predictions['fake_probs'].shape}")
        print(f"    å€¼: {predictions['fake_probs'].tolist()}")
        print(f"  - generator_ids shape: {predictions['generator_ids'].shape}")
        print(f"    å€¼: {predictions['generator_ids'].tolist()}")
        print(f"  - generator_probs shape: {predictions['generator_probs'].shape}")
        print(f"  - forgery_masks shape: {predictions['forgery_masks'].shape}")
        print(f"  - forgery_masks_binary shape: {predictions['forgery_masks_binary'].shape}")
        
    except Exception as e:
        print(f"âœ— Predictæ–¹æ³•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    # 7. æµ‹è¯•æ¢¯åº¦è®¡ç®—ï¼ˆä»…ç”¨äºå‚æ•°éªŒè¯ï¼Œä¸ç”¨äºä¼˜åŒ–ï¼‰
    print("\n[7] éªŒè¯å¯è®­ç»ƒå‚æ•°...")
    trainable_count = sum(p.numel() for p in model.parameters() if p.requires_grad)
    total_count = sum(p.numel() for p in model.parameters())
    print(f"  - å¯è®­ç»ƒå‚æ•°: {trainable_count:,}")
    print(f"  - æ€»å‚æ•°æ•°: {total_count:,}")
    print(f"  - å¯è®­ç»ƒæ¯”ä¾‹: {100 * trainable_count / total_count:.2f}%")
    print(f"     âœ“ å‚æ•°ç»Ÿè®¡å®Œæˆ")
    
    # 8. æœ€ç»ˆæ€»ç»“
    print("\n" + "=" * 80)
    print("âœ“ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ¨¡å‹forward passæ­£ç¡®")
    print("=" * 80)


if __name__ == "__main__":
    test_qwen_vision_forward()
